{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a Noise Model using Bootstrapping\n",
    "\n",
    "Here we assume that we do not have access to calibration data to create a noise model for training DivNoising. In this case, we use an approach called ```Bootstrapping``` to create a noise model from noisy data itself. The idea is that we will first use the unsupervised denoising method Noise2Void to obtain denoised images corresponding to our noisy data. Then we will treat the denoised images as pseudo GT corresponding to the noisy data and use the pair of noisy images and corresponding Noise2Void denoised images to learn a noise model.\n",
    "\n",
    "DivNoising when using bootstrapped noise model generally gives better results compared to Noise2Void denoising. Also, unlike Noise2Void, we additionally obtain diverse denoised samples corresponding to any noisy image unlike Noise2Void.\n",
    "\n",
    "__Note:__ Denoising methods other than Noise2Void can also be used to obtain pseudo GT for bootsrapping a noise model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-28T08:10:27.630567200Z",
     "start_time": "2025-11-28T08:10:25.624876900Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only a single TORCH_LIBRARY can be used to register the namespace prims; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:241; latest registration was registered at /dev/null:241",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m      2\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01murllib\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Software\\Anaconda\\envs\\SMLM_SR\\lib\\site-packages\\torch\\__init__.py:2604\u001B[0m\n\u001B[0;32m   2600\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m vmap \u001B[38;5;28;01mas\u001B[39;00m vmap\n\u001B[0;32m   2603\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m TYPE_CHECKING:\n\u001B[1;32m-> 2604\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _meta_registrations\n\u001B[0;32m   2606\u001B[0m \u001B[38;5;66;03m# Enable CUDA Sanitizer\u001B[39;00m\n\u001B[0;32m   2607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTORCH_CUDA_SANITIZER\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39menviron:\n",
      "File \u001B[1;32mC:\\Software\\Anaconda\\envs\\SMLM_SR\\lib\\site-packages\\torch\\_meta_registrations.py:11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_prims_common\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mutils\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SymBool, SymFloat, Tensor\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_decomp\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     _add_op_to_registry,\n\u001B[0;32m     13\u001B[0m     _convert_out_params,\n\u001B[0;32m     14\u001B[0m     global_decomposition_table,\n\u001B[0;32m     15\u001B[0m     meta_table,\n\u001B[0;32m     16\u001B[0m )\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_ops\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m OpOverload\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_prims\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _prim_elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "File \u001B[1;32mC:\\Software\\Anaconda\\envs\\SMLM_SR\\lib\\site-packages\\torch\\_decomp\\__init__.py:284\u001B[0m\n\u001B[0;32m    280\u001B[0m             decompositions\u001B[38;5;241m.\u001B[39mpop(op, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    283\u001B[0m \u001B[38;5;66;03m# populate the table\u001B[39;00m\n\u001B[1;32m--> 284\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_decomp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdecompositions\u001B[39;00m\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_refs\u001B[39;00m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcore_aten_decompositions\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCustomDecompTable\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32mC:\\Software\\Anaconda\\envs\\SMLM_SR\\lib\\site-packages\\torch\\_decomp\\decompositions.py:15\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_meta_registrations\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_prims\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mprims\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_prims_common\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mutils\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mF\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Software\\Anaconda\\envs\\SMLM_SR\\lib\\site-packages\\torch\\_prims\\__init__.py:36\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moverrides\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m handle_torch_function, has_torch_function\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tree_flatten, tree_map, tree_unflatten\n\u001B[1;32m---> 36\u001B[0m prim \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlibrary\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLibrary\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprims\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDEF\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m prim_impl \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlibrary\u001B[38;5;241m.\u001B[39mLibrary(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprims\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIMPL\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCompositeExplicitAutograd\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     38\u001B[0m prim_backend_select_impl \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlibrary\u001B[38;5;241m.\u001B[39mLibrary(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprims\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIMPL\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBackendSelect\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\Software\\Anaconda\\envs\\SMLM_SR\\lib\\site-packages\\torch\\library.py:93\u001B[0m, in \u001B[0;36mLibrary.__init__\u001B[1;34m(self, ns, kind, dispatch_key)\u001B[0m\n\u001B[0;32m     91\u001B[0m frame \u001B[38;5;241m=\u001B[39m traceback\u001B[38;5;241m.\u001B[39mextract_stack(limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     92\u001B[0m filename, lineno \u001B[38;5;241m=\u001B[39m frame\u001B[38;5;241m.\u001B[39mfilename, frame\u001B[38;5;241m.\u001B[39mlineno\n\u001B[1;32m---> 93\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mm: Optional[Any] \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch_library\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkind\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdispatch_key\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlineno\u001B[49m\n\u001B[0;32m     95\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mns \u001B[38;5;241m=\u001B[39m ns\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_op_defs: Set[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Only a single TORCH_LIBRARY can be used to register the namespace prims; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:241; latest registration was registered at /dev/null:241"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "from torch.distributions import normal\n",
    "import matplotlib.pyplot as plt, numpy as np, pickle\n",
    "from scipy.stats import norm\n",
    "from tifffile import imread\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from DivNoising.divnoising.gaussianMixtureNoiseModel import GaussianMixtureNoiseModel\n",
    "from DivNoising.divnoising import histNoiseModel\n",
    "from DivNoising.divnoising.utils import plotProbabilityDistribution\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "Download the data from https://zenodo.org/record/5156960/files/Mouse%20skull%20nuclei.zip?download=1. Here we show the pipeline for Convallaria dataset. Save the dataset in an appropriate path. For us, the path is the data folder which exists at `./data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observation= imread('./data/Mouse_skull_nuclei/edgeoftheslide_300offset.tif') #Load the noisy data to be denoised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pseudo GT\n",
    "\n",
    "As described above, we will use the denoising results obtained by Noise2Void and treat them as pseudo GT corresponding to our noisy data. Following this, we will use the pair of noisy images and corresponding Noise2Void denoised images to learn a noise model. You can use any other denoising method as well and treat their denoised result as pseudo GT to learn a noise model for DivNoising training.\n",
    "\n",
    "If you have access to pseudo GT (denoised images from some other denoising method), provide the directory path for these images in ```pseudo_gt_path``` parameter. If you do not have such pseudo GT, first generate these images by running any denoising method on your data. For example, you can use Noise2Void denoising as shown [here](https://github.com/juglab/n2v).\n",
    "\n",
    "Next, specify the directory path (```noisy_input_path```) to the noisy data that you wish to denoise with DivNoising.\n",
    "\n",
    "Using these, we can either bin the noisy - pseudo GT pairs as a 2-D histogram or fit a GMM distribution to obtain a smooth, parametric description of the noise model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pseudo_gt_path=\"./pseudo_gt/\"\n",
    "signal = imread(pseudo_gt_path+'*.tif') # Load pseudo GT (obtained as a result of denoising from other methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify ```path``` where the noisy data will be loaded from. It is the same path where noise model will be stored when created later, ```dataName``` is the name you wish to have for the noise model,  ```n_gaussian``` to indicate how mamny Gaussians willbe used for learning a GMM based noise model, ```n_coeff``` for indicating number of polynomial coefficients will be used to patrametrize the mean, standard deviation and weight of GMM noise model. The default settings for ```n_gaussian``` and ```n_coeff``` generally work well for most datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './data/Mouse_skull_nuclei/'\n",
    "dataName = 'mouse_skull_nuclei' # Name of the noise model \n",
    "n_gaussian = 3 # Number of gaussians to use for Gaussian Mixture Model\n",
    "n_coeff = 2 # No. of polynomial coefficients for parameterizing the mean, standard deviation and weight of Gaussian components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nameHistNoiseModel ='HistNoiseModel_'+dataName+'_'+'bootstrap'\n",
    "nameGMMNoiseModel = 'GMMNoiseModel_'+dataName+'_'+str(n_gaussian)+'_'+str(n_coeff)+'_'+'bootstrap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look the raw data and our pseudo ground truth signal\n",
    "print(signal.shape)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(label='pseudo ground truth')\n",
    "plt.imshow(signal[0],cmap='gray')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(label='single raw image')\n",
    "plt.imshow(observation[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Histogram Noise Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the raw pixels $x_i$, and our averaged GT $s_i$, we are now learning a histogram based noise model. It describes the distribution $p(x_i|s_i)$ for each $s_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We set the range of values we want to cover with our model.\n",
    "# The pixel intensities in the images you want to denoise have to lie within this range.\n",
    "minVal, maxVal = 2000, 22000\n",
    "bins = 400\n",
    "\n",
    "# We are creating the histogram.\n",
    "# This can take a minute.\n",
    "histogram = histNoiseModel.createHistogram(bins, minVal, maxVal, observation,signal)\n",
    "\n",
    "# Saving histogram to disc.\n",
    "np.save(path+nameHistNoiseModel+'.npy', histogram)\n",
    "histogramFD=histogram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the histogram-based noise model.\n",
    "plt.xlabel('Observation Bin')\n",
    "plt.ylabel('Signal Bin')\n",
    "plt.imshow(histogramFD**0.25, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the GMM noise model\n",
    "Using the raw pixels $x_i$, and our averaged GT $s_i$, we are now learning a GMM based noise model. It describes the distribution $p(x_i|s_i)$ for each $s_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_signal=np.percentile(signal, 0.5)\n",
    "max_signal=np.percentile(signal, 99.5)\n",
    "print(\"Minimum Signal Intensity is\", min_signal)\n",
    "print(\"Maximum Signal Intensity is\", max_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_signal=np.min(signal)\n",
    "max_signal=np.max(signal)\n",
    "print(\"Minimum Signal Intensity is\", min_signal)\n",
    "print(\"Maximum Signal Intensity is\", max_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating the noise model training for `n_epoch=4000` and `batchSize=25000` works the best for `Mouse nuclei` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussianMixtureNoiseModel = GaussianMixtureNoiseModel(min_signal = min_signal, max_signal =max_signal, \n",
    "                                                      path=path, weight = None, n_gaussian = n_gaussian, \n",
    "                                                      n_coeff = n_coeff, min_sigma = 50, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussianMixtureNoiseModel.train(signal, observation, batchSize = 25000, n_epochs = 4000, learning_rate=0.1, \n",
    "                                name = nameGMMNoiseModel, lowerClip = 0.5, upperClip = 99.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Histogram-based and GMM-based noise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotProbabilityDistribution(signalBinIndex=170, histogram=histogramFD, \n",
    "                            gaussianMixtureNoiseModel=gaussianMixtureNoiseModel, min_signal=minVal, \n",
    "                            max_signal=maxVal, n_bin= bins, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
